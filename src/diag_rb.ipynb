{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Module for reading NetCDF files\n",
    "\n",
    "Module dependency: -\n",
    "\n",
    "Third-party libraries: xarray, dask, glob\n",
    "\"\"\"\n",
    "\n",
    "def rb_open(ncpath='../post/data/phi.*.nc'):\n",
    "    \"\"\"\n",
    "    Read NetCDF files by xarray\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        ncpath : str\n",
    "            directory path of phi.*.nc\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        xr_dataset : xarray Dataset\n",
    "            xarray Dataset of phi.*.nc\n",
    "    \"\"\"\n",
    "    import xarray as xr\n",
    "    xr_dataset = xr.open_mfdataset(ncpath, combine='by_coords')\n",
    "    # 相対パスは、このプログラム（diag_rb.py）を基準にした位置ではなく、これを呼び出したmain_programから見た相対位置を指定すること！\n",
    "    return xr_dataset\n",
    "\n",
    "\n",
    "def rb_get_tri_filelist(ncpath='../post/data/tri.*.nc'):\n",
    "    \"\"\"\n",
    "    Get a list of NetCDF files tri.mx****my****.***.nc\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        ncpath : str\n",
    "            directory path of tri.mx****my****.***.nc\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tri_filelist : list of str\n",
    "            list of tri.mx****my****\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    tri_filelist=sorted(glob.glob(ncpath))             # tri.*ncに該当するファイル名を取得\n",
    "    tri_filelist=[file[:-7] for file in tri_filelist]  # ファイル名末尾の .***.nc を削除\n",
    "    tri_filelist=sorted(set(tri_filelist))             # 重複したファイル名 tri.mx****my*** はリストから削除\n",
    "    num_triad_diag = len(tri_filelist)\n",
    "    #print(\"num_triad_diag:\", num_triad_diag)\n",
    "    #print(\"tri_filelist:\", tri_filelist)\n",
    "    return tri_filelist\n",
    "\n",
    "def safe_compute(tensor, safety_factor=1.5, enable_logging=False):\n",
    "    \"\"\"\n",
    "    tensor.compute() を呼び出す前に、テンソルのサイズとシステムの使用可能メモリを比較します。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : dask.array.Array または類似のオブジェクト\n",
    "        compute() を呼び出す対象のテンソルです。\n",
    "    safety_factor : float, optional\n",
    "        計算時に発生する一時的なメモリ使用量を見越して、必要メモリに掛ける係数です (デフォルト: 1.5)。\n",
    "    enable_logging : bool, optional\n",
    "        True の場合、ログを標準出力します。\n",
    "    Returns\n",
    "    -------\n",
    "    dask.array.Array または類似のオブジェクト\n",
    "        十分なメモリ領域がある場合は tensor.compute() の結果を返します。\n",
    "        その他の場合は tensor をそのまま返します。\n",
    "    \"\"\"\n",
    "    import psutil\n",
    "    # テンソルのメモリ量をバイト単位で推定します。\n",
    "    # tensor.size と tensor.dtype.itemsize を用いる。\n",
    "    try:\n",
    "        required = tensor.size * tensor.dtype.itemsize * safety_factor\n",
    "    except AttributeError:\n",
    "        raise TypeError(\"The input tensor must have 'size' and 'dtype.itemsize' attributes.\")\n",
    "\n",
    "    # システムの利用可能メモリをバイト単位で取得します。\n",
    "    avail = psutil.virtual_memory().available\n",
    "\n",
    "    # メモリ量を標準出力します。\n",
    "    if enable_logging:\n",
    "        print(f\"safe_compute(): Required memory (with safety factor {safety_factor}): {required / (1024**3):.2f} GB\")\n",
    "        print(f\"safe_compute(): Available memory: {avail / (1024**3):.2f} GB\")\n",
    "\n",
    "    if required < avail:\n",
    "        # 十分なメモリ領域がある場合、compute() を実行します。\n",
    "        if enable_logging:\n",
    "            print(\"safe_compute(): Sufficient memory available. Proceeding with compute().\")\n",
    "        return tensor.compute()\n",
    "    else:\n",
    "        # 十分なメモリ領域がない場合はそのまま返します。\n",
    "        if enable_logging:\n",
    "            print(f\"safe_compute(): Not enough memory to compute() tensor.\")\n",
    "        return tensor\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    xr_phi = rb_open('../../post/data/phi.*.nc')\n",
    "    print(\"xr_phi\", xr_phi, \"\\n\")\n",
    "    xr_Al = rb_open('../../post/data/Al.*.nc')\n",
    "    print(\"xr_Al\", xr_Al, \"\\n\")\n",
    "    xr_mom = rb_open('../../post/data/mom.*.nc')\n",
    "    print(\"xr_mom\", xr_mom, \"\\n\")\n",
    "    xr_fxv = rb_open('../../post/data/fxv.*.nc')\n",
    "    print(\"xr_fxv\", xr_fxv, \"\\n\")\n",
    "    xr_cnt = rb_open('../../post/data/cnt.*.nc')\n",
    "    print(\"xr_cnt\", xr_cnt, \"\\n\")\n",
    "    xr_trn = rb_open('../../post/data/trn.*.nc')\n",
    "    print(\"xr_trn\", xr_trn, \"\\n\")\n",
    "\n",
    "    tri_filelist = rb_get_tri_filelist('../../post/data/tri.*.nc')\n",
    "    print(tri_filelist)\n",
    "    xr_tri_list=[]\n",
    "    for file in tri_filelist:\n",
    "        xr_tri=rb_open(file + '.*.nc')\n",
    "        xr_tri_list.append(xr_tri)\n",
    "        print(\"xr_tri\", xr_tri, \"\\n\")\n",
    "\n",
    "    import dask.array as da\n",
    "    x = da.random.random((1000, 100, 10))\n",
    "    result = safe_compute(x, safety_factor=1e6, enable_logging=True)\n",
    "    result = safe_compute(x, enable_logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
